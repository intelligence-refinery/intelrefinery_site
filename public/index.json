[{"categories":["Data science toolbox"],"contents":"       \n --       \n One of the most exciting things about data science is when you get your hands on a new dataset. Oh, the sense of possibilities when opening up a new dataset!\nUnfortunately, before you can get to the fun stuff (though who said that EDA can’t be fun), it’s important to get an idea of its overall structure and potential problems. Here is a round up of our favourite packages for getting acquainted with a dataset while writing a minimum amount of code.\nesquisse: interactive data exploration with ggplot2 If you are really impatient, esquisse is an RStudio addin that launches a point-and-click GUI for absolutely no-code interactive EDA. After drag-and-drop selection of the features that you want to visualize, it not only generates customized beautiful ggplot2 figures but also exports the code so that you can easily replicate them elsewhere.\nFrom its official documentation:\nesquisse can also be used as a module inside your Shiny application.\n dataMaid: quality check of raw data To quickly spot things like missing values, misclassified variables, and erroneous values, I prefer dataMaid for its straight forward combination of metrics and visualizations.\n## Import library library(\u0026#39;dataMaid\u0026#39;) ## Import data raw Telco customer churn dataset raw_df \u0026lt;- read.csv(\u0026quot;https://github.com/treselle-systems/customer_churn_analysis/raw/master/WA_Fn-UseC_-Telco-Customer-Churn.csv\u0026quot;) dataMaid generates a summary report of your dataset in R markdown format, which you can knit together into an PDF or HTML report. For demonstration purposes, I will just show snippets of the interesting parts:\n## Generate report makeDataReport(raw_df, openResult = TRUE, output=\u0026#39;html\u0026#39;, render = TRUE, file = \u0026quot;./auto_eda_report.Rmd\u0026quot;, replace = TRUE, codebook=TRUE) First part of the generated report shows the types of checks performed:\n   Then, we see a summary table of all variables, which provides a helpful quick overview of the data and any potential issues, like the 0.16% missing data in the TotalCharges column.\n   Scrolling down, there are more detailed information on each variable. We see problematic areas such as the customerID column being a key and that the SeniorCitizen column is encoded in 0s and 1s.\n   Also we see that the minimum value of Tenure column is 0, which is problematic and should be removed.\n   Of all the automated EDA packages in R and Python that I have tried so far, dataMaid provides the best once-over, quick-glance view of the whole dataset with a single function. These results are great for focusing the initial data cleaning process.\n autoEDA: quick overview of cleaned data Once I get a (reasonably) clean data set, I want to be able to explore the variables and their relationships with minimal coding (at first). This is where the next two packages come in, which provide varying degrees of flexibility and depth of insights.\nFor the first quick overview, I use the autoEDA package to explore the relationship between all input variables and my target variable of interest, which is Churn in this case. For maximum convenience, this is can be done in a single line of code:\n## Import libraries library(autoEDA) ## Import the same dataset, but with basic cleaning cleaned_df \u0026lt;- read.csv(\u0026quot;https://github.com/nchelaru/data-prep/raw/master/telco_cleaned_yes_no.csv\u0026quot;) ## Correctly format the target variable cleaned_df$Churn \u0026lt;- as.character(cleaned_df$Churn) ## autoEDA autoEDA_results \u0026lt;- autoEDA(cleaned_df, y = \u0026quot;Churn\u0026quot;, returnPlotList = TRUE, verbose = FALSE)  The graphical outputs provided by autoEDA give very quick at-a-glance insights into how various aspects of customer demographics and behaviour relate to whether they churn or not. As there are many plots, one for each variable plus some more, I will show them in a nifty carousel made possible by the slickR package:\n## Import libraries library(svglite) library(lattice) library(ggplot2) library(rvest) library(reshape2) library(dplyr) library(htmlwidgets) library(slickR) ## Create list of autoEDA figures converted to SVG plotsToSVG \u0026lt;- list() i \u0026lt;- 1 for (v in autoEDA_results$plots) { x \u0026lt;- xmlSVG({show(v)}, standalone=TRUE) plotsToSVG[[i]] \u0026lt;- x i \u0026lt;- i +1 } ## Custom function needed to render SVGs in Chrome/Firefox hash_encode_url \u0026lt;- function(url){ gsub(\u0026quot;#\u0026quot;, \u0026quot;%23\u0026quot;, url) } ## Pass list of figures to SlickR s.in \u0026lt;- sapply(plotsToSVG, function(sv){hash_encode_url(paste0(\u0026quot;data:image/svg+xml;utf8,\u0026quot;,as.character(sv)))}) slickR(s.in, slideId = \u0026#39;ex4\u0026#39;,slickOpts = list(dots=T), width = \u0026#39;100%\u0026#39;) #htmlwidget-8f1773b6fe181ad14286 {margin-left:auto;margin-right:auto}  {\"x\":[{\"divName\":\"ex4\",\"divType\":\"img\",\"padding\":\"99%\",\"obj\":[\"data:image/svg+xml;utf8,\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0%\\n \\n \\n 20%\\n \\n \\n 40%\\n \\n \\n 60%\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n No\\n \\n \\n Yes\\n \\n \\n Churn\\n \\n \\n Relative Frequency\\n \\n \\n \\n Churn\\n \\n \\n \\n \\n No\\n \\n \\n Yes\\n \\n \\n Outcome distribution\\n \\n\\n\",\"data:image/svg+xml;utf8,\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0%\\n \\n \\n 25%\\n \\n \\n 50%\\n \\n \\n 75%\\n \\n \\n 100%\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n No\\n \\n \\n Yes\\n \\n \\n Churn\\n \\n \\n Relative Frequency\\n \\n \\n \\n Gender\\n \\n \\n \\n \\n FEMALE\\n \\n \\n MALE\\n \\n \\n Distribution: Churn By Gender\\n \\n\\n\",\"data:image/svg+xml;utf8,\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0%\\n \\n \\n 25%\\n \\n \\n 50%\\n \\n \\n 75%\\n \\n \\n 100%\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n No\\n \\n \\n Yes\\n \\n \\n Churn\\n \\n \\n Relative Frequency\\n \\n \\n \\n SeniorCitizen\\n \\n \\n \\n \\n NO\\n \\n \\n YES\\n \\n \\n Distribution: Churn By SeniorCitizen\\n \\n\\n\",\"data:image/svg+xml;utf8,\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0%\\n \\n \\n 25%\\n \\n \\n 50%\\n \\n \\n 75%\\n \\n \\n 100%\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n No\\n \\n \\n Yes\\n \\n \\n Churn\\n \\n \\n Relative Frequency\\n \\n \\n \\n Partner\\n \\n \\n \\n \\n NO\\n \\n \\n YES\\n \\n \\n Distribution: Churn By Partner\\n \\n\\n\",\"data:image/svg+xml;utf8,\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0%\\n \\n \\n 25%\\n \\n \\n 50%\\n \\n \\n 75%\\n \\n \\n 100%\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n No\\n \\n \\n Yes\\n \\n \\n Churn\\n \\n \\n Relative Frequency\\n \\n \\n \\n Dependents\\n \\n \\n \\n \\n NO\\n \\n \\n YES\\n \\n \\n Distribution: Churn By Dependents\\n \\n\\n\",\"data:image/svg+xml;utf8,\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0\\n \\n \\n 200\\n \\n \\n 400\\n \\n \\n 600\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0\\n \\n \\n 20\\n \\n \\n 40\\n \\n \\n 60\\n \\n \\n Tenure\\n \\n \\n Frequency\\n \\n \\n \\n Churn\\n \\n \\n \\n \\n No\\n \\n \\n Yes\\n \\n \\n Distribution: Tenure By Churn\\n \\n\\n\",\"data:image/svg+xml;utf8,\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0%\\n \\n \\n 25%\\n \\n \\n 50%\\n \\n \\n 75%\\n \\n \\n 100%\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n No\\n \\n \\n Yes\\n \\n \\n Churn\\n \\n \\n Relative Frequency\\n \\n \\n \\n PhoneService\\n \\n \\n \\n \\n NO\\n \\n \\n YES\\n \\n \\n Distribution: Churn By PhoneService\\n \\n\\n\",\"data:image/svg+xml;utf8,\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0%\\n \\n \\n 25%\\n \\n \\n 50%\\n \\n \\n 75%\\n \\n \\n 100%\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n No\\n \\n \\n Yes\\n \\n \\n Churn\\n \\n \\n Relative Frequency\\n \\n \\n \\n MultipleLines\\n \\n \\n \\n \\n NO\\n \\n \\n YES\\n \\n \\n Distribution: Churn By MultipleLines\\n \\n\\n\",\"data:image/svg+xml;utf8,\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0%\\n \\n \\n 25%\\n \\n \\n 50%\\n \\n \\n 75%\\n \\n \\n 100%\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n No\\n \\n \\n Yes\\n \\n \\n Churn\\n \\n \\n Relative Frequency\\n \\n \\n \\n InternetService\\n \\n \\n \\n \\n \\n DSL\\n \\n \\n FIBER OPTIC\\n \\n \\n NO\\n \\n \\n Distribution: Churn By InternetService\\n \\n\\n\",\"data:image/svg+xml;utf8,\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0%\\n \\n \\n 25%\\n \\n \\n 50%\\n \\n \\n 75%\\n \\n \\n 100%\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n No\\n \\n \\n Yes\\n \\n \\n Churn\\n \\n \\n Relative Frequency\\n \\n \\n \\n OnlineSecurity\\n \\n \\n \\n \\n NO\\n \\n \\n YES\\n \\n \\n Distribution: Churn By OnlineSecurity\\n \\n\\n\",\"data:image/svg+xml;utf8,\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0%\\n \\n \\n 25%\\n \\n \\n 50%\\n \\n \\n 75%\\n \\n \\n 100%\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n No\\n \\n \\n Yes\\n \\n \\n Churn\\n \\n \\n Relative Frequency\\n \\n \\n \\n OnlineBackup\\n \\n \\n \\n \\n NO\\n \\n \\n YES\\n \\n \\n Distribution: Churn By OnlineBackup\\n \\n\\n\",\"data:image/svg+xml;utf8,\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0%\\n \\n \\n 25%\\n \\n \\n 50%\\n \\n \\n 75%\\n \\n \\n 100%\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n No\\n \\n \\n Yes\\n \\n \\n Churn\\n \\n \\n Relative Frequency\\n \\n \\n \\n DeviceProtection\\n \\n \\n \\n \\n NO\\n \\n \\n YES\\n \\n \\n Distribution: Churn By DeviceProtection\\n \\n\\n\",\"data:image/svg+xml;utf8,\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0%\\n \\n \\n 25%\\n \\n \\n 50%\\n \\n \\n 75%\\n \\n \\n 100%\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n No\\n \\n \\n Yes\\n \\n \\n Churn\\n \\n \\n Relative Frequency\\n \\n \\n \\n TechSupport\\n \\n \\n \\n \\n NO\\n \\n \\n YES\\n \\n \\n Distribution: Churn By TechSupport\\n \\n\\n\",\"data:image/svg+xml;utf8,\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0%\\n \\n \\n 25%\\n \\n \\n 50%\\n \\n \\n 75%\\n \\n \\n 100%\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n No\\n \\n \\n Yes\\n \\n \\n Churn\\n \\n \\n Relative Frequency\\n \\n \\n \\n StreamingTV\\n \\n \\n \\n \\n NO\\n \\n \\n YES\\n \\n \\n Distribution: Churn By StreamingTV\\n \\n\\n\",\"data:image/svg+xml;utf8,\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0%\\n \\n \\n 25%\\n \\n \\n 50%\\n \\n \\n 75%\\n \\n \\n 100%\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n No\\n \\n \\n Yes\\n \\n \\n Churn\\n \\n \\n Relative Frequency\\n \\n \\n \\n StreamingMovies\\n \\n \\n \\n \\n NO\\n \\n \\n YES\\n \\n \\n Distribution: Churn By StreamingMovies\\n \\n\\n\",\"data:image/svg+xml;utf8,\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0%\\n \\n \\n 25%\\n \\n \\n 50%\\n \\n \\n 75%\\n \\n \\n 100%\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n No\\n \\n \\n Yes\\n \\n \\n Churn\\n \\n \\n Relative Frequency\\n \\n \\n \\n Contract\\n \\n \\n \\n \\n \\n MONTH-TO-MONTH\\n \\n \\n ONE YEAR\\n \\n \\n TWO YEAR\\n \\n \\n Distribution: Churn By Contract\\n \\n\\n\",\"data:image/svg+xml;utf8,\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0%\\n \\n \\n 25%\\n \\n \\n 50%\\n \\n \\n 75%\\n \\n \\n 100%\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n No\\n \\n \\n Yes\\n \\n \\n Churn\\n \\n \\n Relative Frequency\\n \\n \\n \\n PaperlessBilling\\n \\n \\n \\n \\n NO\\n \\n \\n YES\\n \\n \\n Distribution: Churn By PaperlessBilling\\n \\n\\n\",\"data:image/svg+xml;utf8,\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0%\\n \\n \\n 25%\\n \\n \\n 50%\\n \\n \\n 75%\\n \\n \\n 100%\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n No\\n \\n \\n Yes\\n \\n \\n Churn\\n \\n \\n Relative Frequency\\n \\n \\n \\n PaymentMethod\\n \\n \\n \\n \\n \\n \\n BANK TRANSFER (AUTOMATIC)\\n \\n \\n CREDIT CARD (AUTOMATIC)\\n \\n \\n ELECTRONIC CHECK\\n \\n \\n MAILED CHECK\\n \\n \\n Distribution: Churn By PaymentMethod\\n \\n\\n\",\"data:image/svg+xml;utf8,\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0\\n \\n \\n 250\\n \\n \\n 500\\n \\n \\n 750\\n \\n \\n 1000\\n \\n \\n 1250\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 25\\n \\n \\n 50\\n \\n \\n 75\\n \\n \\n 100\\n \\n \\n MonthlyCharges\\n \\n \\n Frequency\\n \\n \\n \\n Churn\\n \\n \\n \\n \\n No\\n \\n \\n Yes\\n \\n \\n Distribution: MonthlyCharges By Churn\\n \\n\\n\",\"data:image/svg+xml;utf8,\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0\\n \\n \\n 500\\n \\n \\n 1000\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0\\n \\n \\n 2500\\n \\n \\n 5000\\n \\n \\n 7500\\n \\n \\n TotalCharges\\n \\n \\n Frequency\\n \\n \\n \\n Churn\\n \\n \\n \\n \\n No\\n \\n \\n Yes\\n \\n \\n Distribution: TotalCharges By Churn\\n \\n\\n\",\"data:image/svg+xml;utf8,\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0%\\n \\n \\n 25%\\n \\n \\n 50%\\n \\n \\n 75%\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n Low\\n \\n \\n Medium\\n \\n \\n PredictivePower\\n \\n \\n Relative Frequency\\n \\n \\n \\n PredictivePower\\n \\n \\n \\n \\n Low\\n \\n \\n Medium\\n \\n \\n Predictive power of features\\n \\n\\n\"],\"slickOpts\":{\"dots\":true}}],\"evals\":[],\"jsHooks\":[]} \nIt is important to keep in mind that this type of bivariate analysis cannot detect combinatorial effects that exist among multiple variables to affect churn. Therefore, just because a variable do not appear to be differently distributed in terms of churn behaviour, such as Gender, it should not be excluded from analysis as it may be significant when considered in combination with other variables. Nevertheless, this is a good start for seeing if there are “learnable” signals in the dataset.\nThe output also includes a dataframe with summary statistics pertaining to variable type, presence of outliers, and descriptive statistics.\n## Import libraries library(knitr) library(kableExtra) ## Preview data kable(t(head(autoEDA_results$overview, 4)), colnames=NULL) %\u0026gt;% kable_styling(bootstrap_options = c(\u0026quot;striped\u0026quot;, \u0026quot;hover\u0026quot;))    1  2  3  4      Feature  Churn  Contract  Dependents  DeviceProtection    Observations  7032  7032  7032  7032    FeatureClass  character  character  character  character    FeatureType  Categorical  Categorical  Categorical  Categorical    PercentageMissing  0  0  0  0    PercentageUnique  0.03  0.04  0.03  0.03    ConstantFeature  No  No  No  No    ZeroSpreadFeature  No  No  No  No    LowerOutliers  0  0  0  0    UpperOutliers  0  0  0  0    ImputationValue  NO  MONTH-TO-MONTH  NO  NO    MinValue  0  0  0  0    FirstQuartile  0  0  0  0    Median  0  0  0  0    Mean  0  0  0  0    Mode  NO  MONTH-TO-MONTH  NO  NO    ThirdQuartile  0  0  0  0    MaxValue  0  0  0  0    LowerOutlierValue  0  0  0  0    UpperOutlierValue  0  0  0  0    PredictivePowerPercentage  0  46  17  7    PredictivePower  Low  Medium  Low  Low     In the last row, there is a handy PredictivePower metric for each input variable with respect to a specified target variable. For now, we can ignore this as I will cover it in more details in a later post examining variable importance.\n ExPanDaR: your own Shiny app for data exploration ExPanDaR provides a really nifty Shiny app for interactive explorations of your data set. Originally designed for examining time-series data, the package requires the input dataframe to have a 1) time/date column and 2) a column that uniquely identifies each row. As the time/date column is only needed if you want to visualize time-dependent trends, to use a dataset without a time dimension you can just add a new numeric column (ts) with a constant and set that as the time dimension. An index column would suffice for the second requirement. In the original Telco dataset, the customerID column would have worked fine. As I had dropped it in the process of data cleaning, I will just add a new index column (ID).\n## Import library library(ExPanDaR) ## Add mock time column and new index to dataframe cleaned_df$ts \u0026lt;- rep(1, nrow(cleaned_df)) cleaned_df$ID \u0026lt;- seq.int(nrow(cleaned_df)) To start up the Shiny app for interactive exploration of the results:\nExPanD(df = cleaned_df, cs_id = \u0026quot;ID\u0026quot;, ts_id = \u0026quot;ts\u0026quot;) Here are some snapshots of the features that I find most useful. The dropdown menus and sliders make it really easy and flexible to examine any combinations of variables.\n         To go beyond bivariate relationships, the scatter plot can aggregate information from up to four variables and really give some interesting insights.\n   There are some other very cool features like allowing the user to generate and explore new variables (from some arithemtic combinations of existing variables) on the fly and performing regression analysis. Definitely give this package a try!\n     ","permalink":"/post/fast-exploratory-data-analysis-for-the-impatient/","tags":["EDA","R","Visualizations"],"title":"Fast exploratory data analysis for when you just can't wait"},{"categories":["Data science toolbox"],"contents":" \n --       \n As useful as they are, and they really are, Jupyter notebooks can feel rather stale after a few years. While they are great for quickly testing out code and exploring datasets, I can’t help but want something more fun and polished for presenting a completed project.\nFor this reason I had been working largely in R for the past while, despite my preference for the simplicity of the Python syntax, in large part due to the vibrant Shiny ecosystem that makes creating dashboards and interactive web apps easy and fun. However, I am happy to report that in really just the past year or so, the interactive app/dashboard scene in Python has really flourished, first with the appearance of the Plotly Dash platform and then most recently with Streamlit. Here is a (ever updating) round-up of my experiences so far with Python packages that allow us to bring our data science projects to life.\nStreamlit What really drew me back to Python is the appearance of Streamlit, an open-source library that really truly makes converting a data analysis workflow to an app a breeze. By adding a few magic commands, a Python script is spun to an interactive app that can be deployed on Heroku like any other web app.\n\n \nInitially, Streamlit seemed to me neither here nor there, sitting somewhere between Plotly Dash and Jupyter notebooks. While it seemed very easy to worked with, I thought that it was missing the “look” of Dash and also the versatility of cell-based operations of Jupyter. However, as soon as I gave it a try, I totally understood the allure.\nThe absolute best feature of Streamlit, in my opinion, is how easy it is to create interactive widgets like dropdown menus, radio boxes, sliders and even text/number inputs, without needing to write any callbacks. Using an example from the official documentation, this is how to create and get input from a slider:\nimport streamlit as st age = st.slider(\u0026#39;How old are you?\u0026#39;, 0, 130, 25) st.write(\u0026quot;I\u0026#39;m \u0026quot;, age, \u0026#39;years old\u0026#39;) Creating other types of interactive widgets in Streamlit is just as easy. You can find a list of functionalities currently supported here.\nIn comparison, this is how to create the same thing in Plotly Dash:\nimport dash import dash_html_components as html import dash_core_components as dcc app = dash.Dash(__name__, external_stylesheets=external_stylesheets) app.layout = html.Div([ dcc.Slider( id=\u0026#39;my-slider\u0026#39;, min=0, max=20, step=0.5, value=10, ), html.Div(id=\u0026#39;slider-output-container\u0026#39;) ]) @app.callback( dash.dependencies.Output(\u0026#39;slider-output-container\u0026#39;, \u0026#39;children\u0026#39;), [dash.dependencies.Input(\u0026#39;my-slider\u0026#39;, \u0026#39;value\u0026#39;)]) def update_output(value): return \u0026#39;You have selected \u0026quot;{}\u0026quot;\u0026#39;.format(value) if __name__ == \u0026#39;__main__\u0026#39;: app.run_server(debug=True)  Of course, Plotly Dash provides many other functionalities that Streamlit is not capable of, at least for now. However, the simplicity of working with Streamlit makes it so satistfying to quickly whip up an interactive app to showcase your work.\nFor example, I have made two Streamlit apps to host my microlearning series on survival analysis and building a random forest classifier to predict customer churn. I made them both multipage apps that allow progressive reveal of the content at the learner’s pace, in order to take advantage of the easy interactive widgets to the fullest extent. Granted that I had the workflow written out before hand, but making either one of these apps took only 2-3 days. Check out this one about integrating unsupervised and supervised machine learning!\n\n If you are interested in trying Streamlit out, there are several demo apps listed in the documentation linked above. In addition, many enthusiastic adopters of Streamlit have tweeted about their own creations.\n Plotly Dash Plotly Dash has been around for quite a while now, so I will not go as much in depth here, trusting that everyone is already pretty familiar with it. Unlike the other two packages introduced here, Dash has the benefit of the very large and active Plotly community to serve as a solid knowledge base to support users of all levels.\nAs of now, Plotly Dash just cannot be beat in terms of how polished its end products look. It is my package of choice if I need to create a dashboard/app that will be used by non-technical end users, such as business professionals, with clear interactive features and sophisticated crosstalk between elements (i.e. data tables, plots, maps, etc.). For example, here is a sales dashboard that I had made while learning the Dash platform.\n  However, as mentioned in comparison with Streamlit, the Dash code base can get quite large and complex very quickly, particularly when used with the built-in or Bootstrap grid system for layout. Consequently, it has a fairly steep learning curve, with very rewarding results. On a related note, I cannot recommend enough the Dash Bootstrap Components package, which greatly simplifies the implementations of a lot of layout and interactive features with the added benefit of the clean Bootstrap look.\nWant to get started on your own? For an step-by-step guide to building a professional dashboard, take a look at the video below made by a Plotly developer:\n \n Voilà Finally, just because we want to upgrade from Jupyter notebooks does not mean we are going to do away with it completely, as it is still a fantastic platform for exploring data and prototyping analysis workflows. In addition, the ability to use Python and R together in the same notebook makes it indispensible for data scientists who want the best of both worlds: ease of data wrangling in Python but mature analysis packages in R. Since so many of us begin a project in Jupyter notebooks, it would be a dream come true to be able to make dashboards/interactive apps from the analysis results right there. The recently released package Voilà grants that wish, somewhat.\nHere is an introduction to the package at SciPy 2019:\n\n \nWhile interactive widgets like dropdown menus and sliders can be added to the dashboard, as you can do in Streamlit and Plotly Dash, using the ipywidgets library, I have personally found the syntax much less clear and not as many tutorials/help pages available to get a newcomer started. In addition, as Voilà is still in very early stages of development, the resulting dashboard/app looks rather barebones as compared to Dash.\nHere is an “learning dashboard” that I had made using Voilà to introduce various model-agnostic approaches to calculate feature importance, for comparison with the sales dashboard made with Dash.\n  Nevertheless, as mentioned above, one strength of Jupyter notebooks is the ability to use other language kernels. Any language that is supported by a Jupyter kernel can be used to create a Voilà app, so for projects where that is needed, this would be the package for you.\n \nTaken together, it is really an exciting time for finally being able to communicate/present your Python data science projects in style. This post will be updated as new features and packages become available, so please check back once in a while! :)\n     ","permalink":"/post/making-python-apps/","tags":["Dash","Jupyter","Python","Streamlit","Voila"],"title":"Going beyond Jupyter notebooks"},{"categories":["Data science toolbox"],"contents":" \n --       \n We are always going to need Matplotlib and Seaborn, but it is so great to see new Python plotting packages popping up in the past few years. In addition to showcasing them here, we will document the little tricks and gotchas that we come across along the way.\nPlotly Express Plotly does not need much introduction, as it is now very widely used to create interactive plots in both Python and R. For a while, one major drawback of Plotly is its rather inconvenient syntax, where the source data needs to be passed in as arrays even though most of us want to be able to plot data directly from dataframes.\nWith the release of Plotly Express with its succinct Seaborn-like one-liner syntax, however, the situation is now much improved. While not all Plotly graphs can be made this way, there is an impressive variety of plots available in the Plotly Express library, including interactive maps.\nOne small annoyance is that the legends in graphs made using Plotly Express are cluttered by the column names. Following the useful tip here, you can use the .for_each_trace() function call to remove them. For example, here we will replace species= with an empty space:\nimport plotly.express as px iris = px.data.iris() fig = px.scatter(iris, x=\u0026quot;sepal_width\u0026quot;, y=\u0026quot;sepal_length\u0026quot;).for_each_trace(lambda t: t.update(name=t.name.replace(\u0026quot;species=\u0026quot;,\u0026quot;\u0026quot;)))    Here is a collection of useful links curated by us for all things Plotly:\n \nYellowbrick This package, built on top of Matplotlib, facilitates visualizing a variety of information from various stages of machine learning workflows. It is a sizable library, and looking through its API is an education in itself.\nWe have not had many chances to use Yellowbrick yet, but are looking forward to being able to delve deeper into this package in the future!\n\nPlotnine One of the strengths of the R language is its very powerful graphing package ggplot2, with its distinctive implementation of Leland Wilkinson’s Grammar of Graphics. The Plotnine package brings this (at least part of it, it seems for now) capability to Python, with very little change to the R syntax.\nThe brackets around the ggplot() function call looks strange at first, but it is needed for the signature multi-line ggplot2 grammer to work:\n## Import libraries import pandas as pd from plotnine import * from random import randint # Generate dataset random_numbers = [randint(1, 100) for p in range(0, 100)] df = pd.DataFrame({\u0026#39;number\u0026#39;: random_numbers}) # Draw plot p = ( ggplot(df, aes(x=\u0026#39;number\u0026#39;)) + geom_histogram(bins=20, na_rm=True) + ggtitle(\u0026#39;Histogram of random numbers\u0026#39;) + theme_light() ) ## Display plot p.draw(); If you want to save the plot to file:\np.save(\u0026quot;output.png\u0026quot;) And just because I can see myself wanting to use these plots in a Streamlit app, here is a working template:\nimport pandas as pd import numpy as np from plotnine import * import streamlit as st n = 10 df = pd.DataFrame({\u0026#39;x\u0026#39;: np.arange(n), \u0026#39;y\u0026#39;: np.arange(n), \u0026#39;yfit\u0026#39;: np.arange(n) + np.tile([-.2, .2], n // 2), \u0026#39;cat\u0026#39;: [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;] * (n // 2)}) a = ( ggplot(df) + geom_col(aes(\u0026#39;x\u0026#39;, \u0026#39;y\u0026#39;)) ) fig = a.draw(); ## Needed to remove the \u0026quot;ggplot\u0026lt;#\u0026gt;\u0026quot; message st.pyplot() Finally, as always, here is a (ever growing) collection of links curated by us to get your started with using Plotnine:\n     ","permalink":"/post/graphing-in-python-a-walkthrough/","tags":["Python","Visualizations"],"title":"Graphing in Python - New(er) kids on the block"},{"categories":["Natural language processing"],"contents":"    ","permalink":"/post/word-embedding/","tags":[],"title":"Word embedding"},{"categories":["Data science toolbox"],"contents":"       \n --       \n Business applications of data science is obviously a very broad topic, as data-driven approaches are becoming increasingly integrated into corporate practices. For this reason, this collection will begin as a scaffold of the topics that we are currently using or want to become familiar with in the near future. Be sure to check back regularly as we add add more content!\nGetting data    .accordion { background-color: #FCB97D; color: #F2CC8F; cursor: pointer; padding: 14px; width: 100%; border: none; text-align: left; outline: none; font-size: 13px; transition: 0.4s; } .active, .accordion:hover { background-color: #F2CC8F; } .panel { padding: 0 18px; background-color: white; max-height: 0; overflow: hidden; transition: max-height 0.2s ease-out; } h3 { padding-top: 0; font-size: 15px; } .content h3 { margin-bottom: 0; }     Working with Excel files    Read data from Excel file:\nimport pandas as pd df = pd.read_excel(\u0026#39;https://archive.ics.uci.edu/ml/machine-learning-databases/00352/Online%20Retail.xlsx\u0026#39;)  {\"x\":{\"tag\":{\"name\":\"Reactable\",\"attribs\":{\"data\":{\"InvoiceNo\":[[536365],[536365],[536365]],\"StockCode\":[[\"85123A\"],[71053],[\"84406B\"]],\"Description\":[[\"WHITE HANGING HEART T-LIGHT HOLDER\"],[\"WHITE METAL LANTERN\"],[\"CREAM CUPID HEARTS COAT HANGER\"]],\"Quantity\":[6,6,8],\"InvoiceDate\":[\"2010-12-01T08:26:00\",\"2010-12-01T08:26:00\",\"2010-12-01T08:26:00\"],\"UnitPrice\":[2.55,3.39,2.75],\"CustomerID\":[17850,17850,17850],\"Country\":[\"United Kingdom\",\"United Kingdom\",\"United Kingdom\"]},\"columns\":[{\"accessor\":\"InvoiceNo\",\"name\":\"InvoiceNo\",\"type\":\"list\"},{\"accessor\":\"StockCode\",\"name\":\"StockCode\",\"type\":\"list\"},{\"accessor\":\"Description\",\"name\":\"Description\",\"type\":\"list\"},{\"accessor\":\"Quantity\",\"name\":\"Quantity\",\"type\":\"numeric\"},{\"accessor\":\"InvoiceDate\",\"name\":\"InvoiceDate\",\"type\":\"Date\"},{\"accessor\":\"UnitPrice\",\"name\":\"UnitPrice\",\"type\":\"numeric\"},{\"accessor\":\"CustomerID\",\"name\":\"CustomerID\",\"type\":\"numeric\"},{\"accessor\":\"Country\",\"name\":\"Country\",\"type\":\"character\"}],\"defaultPageSize\":10,\"paginationType\":\"numbers\",\"showPageInfo\":true,\"minRows\":1,\"dataKey\":\"e3d7eb06698ef9fb96ced2163802ea0a\"},\"children\":[]},\"class\":\"reactR_markup\"},\"evals\":[],\"jsHooks\":[]} \n  Optical Character Recognition (OCR) of documents    Often, we need to extract data from print or scanned business documents, which is where these packages can come in handy:\n \n  Text parsing using regular expressions    To process OCR results into clean tabular data:\n   Data wrangling Given the topic, here we will focus on replicating common Excel functionalities/tasks in Python and R:\n Pivot tables    More coming soon! \n  Crosstab    More coming soon! \n  Sets    More coming soon! \n  Vlookup    More coming soon! \n  Analysis techniques This will be a collection of more “traditional” business analytics approaches. For machine learning methods, please see a future post devoted to the topic.\n Association rule mining    More coming soon! \n  RFM analysis    More coming soon! \n  Survival analysis    More coming soon! \n  Time-series analysis    More coming soon! \n  Reporting Good results are only useful when they are effectively communicated:\n Dashboards    More coming soon! \n  Presentation slides    More coming soon! \n  Automated reports    More coming soon! \n  var acc = document.getElementsByClassName(\"accordion\"); var i; for (i = 0; i        ","permalink":"/post/data-science-for-business/","tags":["Association rule mining","Python","R","Survival analysis"],"title":"Data science for business"},{"categories":["Dev handbook"],"contents":" \n --       \n  Where do we start with version control? It’s a bit finicky, often neglected, but oh-so important.\nOne of the key components of building good habits is to make the action easy to do. So here we round up the (usual) cheat sheets and some fun tools that make learning/remembering those git commands a little easier.\nCheat sheet Of course, to start us off, the official cheat sheet from Github:\n \nGit Explorer As promised, here is a fun one:\n     ","permalink":"/post/version-control-git-handbook/","tags":["Git"],"title":"Version control with Git"},{"categories":["Web development"],"contents":" \n       \n Making your own website or app is a great creative outlet. This is a continuously updated repository of free (or reasonably priced) resources for spicing up the UI/UX:\nIllustrations For those of us who are utterly not artistically inclined, jazz up landing pages and blog posts with these fantastic free illustration. Many of the images you see on this site are taken from these sites:\n \nIcons \u0026amp; Glyphs Pepper these through out to keep things interesting:\n \nColour schemes For those of us who know what looks good but can’t come up with it on our own, colour palette generators and inspirations are essential:\n     ","permalink":"/post/ui-and-ux-resources/","tags":["UI","UX"],"title":"Handy UI and UX resources "},{"categories":["Careers"],"contents":" \n --       \n There may exist some people in this world who enjoy job hunting, but we have not met one of them yet. As data scientist/developer jobs are becoming more and more popular, it is all the more important to know how to keep track of the most interesting opportunity and make your application to stand out. Here are a continuously updating suite of tools and services that we have tried or want to try for getting that next job.\nResumes One way to get yourself to stop putting off writing or updating your resume is make doing it fun and attractive. Remember the good old days of fiddling with Microsoft Word margins to get that two-column look just right? In recent years, almost too many online resume template/building platforms have popped up to keep track of. Here we have a collection of such platforms that offer at least some level of free services.\nFor creating the “official” resume to be send out, our favourites are CakeResume and Flow CV, as they offer the most innovative interfaces, generous free tiers and just the right amount of flexibility. For something a bit different, Qwilir offers templates to create a single-page web document to display the most salient points of your resume, which can be linked as part of a professional portfolio. Nevertheless, as everyone’s resume needs and aesthetic sensibilities differ, it might be worthwhile to look through each of the links below to find one that you particularly like.\n\n \nFinally, we have not tried it yet, but Resume Worded offers a free AI-powered review of your data science resume to check for important key words.\n    ","permalink":"/post/job-hunting-tools/","tags":["Job search","Resume","Useful"],"title":"Make job hunting fun again (kind of)"},{"categories":["Web development"],"contents":" \n --      h3 {font-size: 24px;}    \n Having made a few websites/web apps using Django, Blogdown and Shiny, some HTML and CSS snippets have turned out to be useful time and time again. Not being professional front-end developers, we thought it would probably be a good idea to create an easy-to-reference repository of them for future projects.\nNavigation Tabs Tabs are a great way to display information that you might want to compare side-by-side. The horizontal layout also helps to save on space. I always opt for the Bootstrap tabsets, as they are very easy and consistent to implement:\n\nTab 1  Tab 2  Tab 3     Image credit: Icons 8       Image credit: Icons 8       Image credit: Icons 8       \nTo make this:\n\u0026lt;div class=\u0026quot;container\u0026quot;\u0026gt; \u0026lt;!-- Nav tabs --\u0026gt; \u0026lt;ul class=\u0026quot;nav nav-pills nav-justified\u0026quot; role=\u0026quot;tablist\u0026quot;\u0026gt; \u0026lt;li class=\u0026quot;nav-item active\u0026quot;\u0026gt; \u0026lt;a class=\u0026quot;nav-link active\u0026quot; data-toggle=\u0026quot;tab\u0026quot; href=\u0026quot;#tab1\u0026quot;\u0026gt;\u0026lt;font size=\u0026quot;+2\u0026quot;\u0026gt;\u0026lt;b\u0026gt;Tab 1\u0026lt;/b\u0026gt;\u0026lt;/font\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;nav-item\u0026quot;\u0026gt; \u0026lt;a class=\u0026quot;nav-link\u0026quot; data-toggle=\u0026quot;tab\u0026quot; href=\u0026quot;#tab2\u0026quot;\u0026gt;\u0026lt;font size=\u0026quot;+2\u0026quot;\u0026gt;\u0026lt;b\u0026gt;Tab 2\u0026lt;/b\u0026gt;\u0026lt;/font\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;nav-item\u0026quot;\u0026gt; \u0026lt;a class=\u0026quot;nav-link\u0026quot; data-toggle=\u0026quot;tab\u0026quot; href=\u0026quot;#tab3\u0026quot;\u0026gt;\u0026lt;font size=\u0026quot;+2\u0026quot;\u0026gt;\u0026lt;b\u0026gt;Tab 3\u0026lt;/b\u0026gt;\u0026lt;/font\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;!-- Tab panes --\u0026gt; \u0026lt;div class=\u0026quot;tab-content\u0026quot;\u0026gt; \u0026lt;div id=\u0026quot;tab1\u0026quot; class=\u0026quot;container tab-pane active\u0026quot;\u0026gt; Tab 1 content \u0026lt;/div\u0026gt; \u0026lt;div id=\u0026quot;tab2\u0026quot; class=\u0026quot;container tab-pane fade\u0026quot;\u0026gt; Tab 2 content \u0026lt;/div\u0026gt; \u0026lt;div id=\u0026quot;tab3\u0026quot; class=\u0026quot;container tab-pane fade\u0026quot;\u0026gt; Tab 3 content \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \nFloating outline When the page has a lot of content, it is very helpful to include a floating table of contents on the side of the page that shows the reader where they are. You can see an example of this on the left!\nAfter experimenting with a few options, I found that the steps outlined here by Aidan Feldman work most easily and the best for Blogdown sites:\n\u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt; \u0026lt;meta name=\u0026quot;viewport\u0026quot; content=\u0026quot;width=device-width, initial-scale=1\u0026quot;\u0026gt; \u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.css\u0026quot; /\u0026gt; \u0026lt;script src=\u0026quot;https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026quot;https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026quot;https://maxcdn.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026quot;https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;body data-spy=\u0026quot;scroll\u0026quot; data-target=\u0026quot;#toc\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;container\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;!-- sidebar, which will move to the top on a small screen --\u0026gt; \u0026lt;div class=\u0026quot;col-sm-2\u0026quot;\u0026gt; \u0026lt;nav id=\u0026quot;toc\u0026quot; data-toggle=\u0026quot;toc\u0026quot; class=\u0026quot;sticky-top\u0026quot; style=\u0026#39;padding-top:40px\u0026#39;\u0026gt;\u0026lt;/nav\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;!-- main content area --\u0026gt; \u0026lt;div class=\u0026quot;col-sm-10\u0026quot;\u0026gt; \u0026lt;!-- Page content --\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \nIf there are headings that you do not want to be included in the outline, you can change the header HTML tag, like \u0026lt;h2\u0026gt;, to \u0026lt;h2 data-toc-skip\u0026gt;.\n\nStyling Font size The font size of specific sections of text can be altered, either by relative change:\n\u0026lt;font size=\u0026quot;+2\u0026quot;\u0026gt;This is bigger text.\u0026lt;/font\u0026gt; Or by setting the absolute size (1-7):\n\u0026lt;font size=\u0026quot;1\u0026quot;\u0026gt;This is really tiny text.\u0026lt;/font\u0026gt; \nCode blocks We love the ability to use both Python and R code in a single Rmarkdown post on Blogdown sites. With that, it would be nice to be able to easily visually distinguish Python and R code blocks. Here are some CSS stylings used on this site:\ncode{ /* Base styling for all code blocks */ padding: 3px 5px; background: #ffffff; border: 1px solid $border-color; border-radius: 3px; color: $text-color-dark; } .python { background: #ffffff; border-color: #F6B156; border-style: dotted; page-break-inside: avoid; font-family: monospace; font-size: 15px; line-height: 1.6; margin-bottom: 1.6em; max-width: 100%; overflow: auto; padding: 1em 1.5em; display: block; word-wrap: break-word; } .r { background: #ffffff; border-color: #03d944; border-style: dotted; page-break-inside: avoid; font-family: monospace; font-size: 15px; line-height: 1.6; margin-bottom: 1.6em; max-width: 100%; overflow: auto; padding: 1em 1.5em; display: block; word-wrap: break-word; }     ","permalink":"/post/neat-html-snippets-to-jazz-up-your-site/","tags":["Useful"],"title":"HTML and CSS snippets to jazz up your site"},{"categories":null,"contents":"Welcome to Intelligence Refinery!\nWe are Nancy and Mihai Chelaru-Centea, two neuroscience majors who not so long ago ditched the lab notebooks for Jupyter notebooks. With the explosion of the data science field, there is a bewildering number of articles, tutorials, Stackoverflow answers, courses and packages on the internet for anyone who cares to look. Like many other newcomers, we are navigating this ever rising sea of information, and often misinformation, with varying degrees of success each day.\nAfter having worked for some time as data scientist/developers and meeting others on the same path, we realized the importance of creating a dedicated repository in which we can continuously refine and grow our professional knowledge, so as to be able to keep pace with this fast moving field. So, we rolled up our sleeves and built this site, where we try to distill everything we are learning about data science, software development, and anything else of interest into helpful nuggets for ourselves and whoever else that may stumble onto this site.\nWe hope that you enjoy your time here, and would love to hear any comments or questions that you have!\n","permalink":"/about/about/","tags":null,"title":"About Us"}]
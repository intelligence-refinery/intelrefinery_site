[{"categories":["Data science toolbox"],"contents":"       \n --       \n One of the most exciting things about data science is when you get your hands on a new dataset. Oh, the sense of possibilities when opening up a new dataset!\nUnfortunately, before you can get to the fun stuff (though who said that EDA can’t be fun), it’s important to get an idea of its overall structure and potential problems. Here is a round up of our favourite packages for getting acquainted with a dataset while writing a minimum amount of code.\ndataMaid: quality check of raw data To quickly spot things like missing values, misclassified variables, and erroneous values, I prefer dataMaid for its straight forward combination of metrics and visualizations.\n## Import library library(\u0026#39;dataMaid\u0026#39;) ## Import data raw Telco customer churn dataset raw_df \u0026lt;- read.csv(\u0026quot;https://github.com/treselle-systems/customer_churn_analysis/raw/master/WA_Fn-UseC_-Telco-Customer-Churn.csv\u0026quot;) dataMaid generates a summary report of your dataset in R markdown format, which you can knit together into an PDF or HTML report. For demonstration purposes, I will just show snippets of the interesting parts:\n## Generate report makeDataReport(raw_df, openResult = TRUE, output=\u0026#39;html\u0026#39;, render = TRUE, file = \u0026quot;./auto_eda_report.Rmd\u0026quot;, replace = TRUE, codebook=TRUE) First part of the generated report shows the types of checks performed:\n   Then, we see a summary table of all variables, which provides a helpful quick overview of the data and any potential issues, like the 0.16% missing data in the TotalCharges column.\n   Scrolling down, there are more detailed information on each variable. We see problematic areas such as the customerID column being a key and that the SeniorCitizen column is encoded in 0s and 1s.\n   Also we see that the minimum value of Tenure column is 0, which is problematic and should be removed.\n   Of all the automated EDA packages in R and Python that I have tried so far, dataMaid provides the best once-over, quick-glance view of the whole dataset with a single function. These results are great for focusing the initial data cleaning process.\n autoEDA: quick overview of cleaned data Once I get a (reasonably) clean data set, I want to be able to explore the variables and their relationships with minimal coding (at first). This is where the next two packages come in, which provide varying degrees of flexibility and depth of insights.\nFor the first quick overview, I use the autoEDA package to explore the relationship between all input variables and my target variable of interest, which is Churn in this case. For maximum convenience, this is can be done in a single line of code:\n## Import libraries library(autoEDA) ## Import the same dataset, but with basic cleaning cleaned_df \u0026lt;- read.csv(\u0026quot;https://github.com/nchelaru/data-prep/raw/master/telco_cleaned_yes_no.csv\u0026quot;) ## Correctly format the target variable cleaned_df$Churn \u0026lt;- as.character(cleaned_df$Churn) ## autoEDA autoEDA_results \u0026lt;- autoEDA(cleaned_df, y = \u0026quot;Churn\u0026quot;, returnPlotList = TRUE, verbose = FALSE)  The graphical outputs provided by autoEDA give very quick at-a-glance insights into how various aspects of customer demographics and behaviour relate to whether they churn or not. As there are many plots, one for each variable plus some more, I will show them in a nifty carousel made possible by the slickR package:\n## Import libraries library(svglite) library(lattice) library(ggplot2) library(rvest) library(reshape2) library(dplyr) library(htmlwidgets) library(slickR) ## Create list of autoEDA figures converted to SVG plotsToSVG \u0026lt;- list() i \u0026lt;- 1 for (v in autoEDA_results$plots) { x \u0026lt;- xmlSVG({show(v)}, standalone=TRUE) plotsToSVG[[i]] \u0026lt;- x i \u0026lt;- i +1 } ## Custom function needed to render SVGs in Chrome/Firefox hash_encode_url \u0026lt;- function(url){ gsub(\u0026quot;#\u0026quot;, \u0026quot;%23\u0026quot;, url) } ## Pass list of figures to SlickR s.in \u0026lt;- sapply(plotsToSVG, function(sv){hash_encode_url(paste0(\u0026quot;data:image/svg+xml;utf8,\u0026quot;,as.character(sv)))}) slickR(s.in, slideId = \u0026#39;ex4\u0026#39;,slickOpts = list(dots=T), width = \u0026#39;100%\u0026#39;) #htmlwidget-8f1773b6fe181ad14286 {margin-left:auto;margin-right:auto}  {\"x\":[{\"divName\":\"ex4\",\"divType\":\"img\",\"padding\":\"99%\",\"obj\":[\"data:image/svg+xml;utf8,\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0.0%\\n \\n \\n 20.0%\\n \\n \\n 40.0%\\n \\n \\n 60.0%\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n No\\n \\n \\n Yes\\n \\n \\n Churn\\n \\n \\n Relative Frequency\\n \\n \\n \\n Churn\\n \\n \\n \\n \\n No\\n \\n \\n Yes\\n \\n \\n Outcome distribution\\n \\n\\n\",\"data:image/svg+xml;utf8,\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0%\\n \\n \\n 25%\\n \\n \\n 50%\\n \\n \\n 75%\\n \\n \\n 100%\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n No\\n \\n \\n Yes\\n \\n \\n Churn\\n \\n \\n Relative Frequency\\n \\n \\n \\n Gender\\n \\n \\n \\n \\n FEMALE\\n \\n \\n MALE\\n \\n \\n Distribution: Churn By Gender\\n \\n\\n\",\"data:image/svg+xml;utf8,\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0%\\n \\n \\n 25%\\n \\n \\n 50%\\n \\n \\n 75%\\n \\n \\n 100%\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n No\\n \\n \\n Yes\\n \\n \\n Churn\\n \\n \\n Relative Frequency\\n \\n \\n \\n SeniorCitizen\\n \\n \\n \\n \\n NO\\n \\n \\n YES\\n \\n \\n Distribution: Churn By SeniorCitizen\\n \\n\\n\",\"data:image/svg+xml;utf8,\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0%\\n \\n \\n 25%\\n \\n \\n 50%\\n \\n \\n 75%\\n \\n \\n 100%\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n No\\n \\n \\n Yes\\n \\n \\n Churn\\n \\n \\n Relative Frequency\\n \\n \\n \\n Partner\\n \\n \\n \\n \\n NO\\n \\n \\n YES\\n \\n \\n Distribution: Churn By Partner\\n \\n\\n\",\"data:image/svg+xml;utf8,\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0%\\n \\n \\n 25%\\n \\n \\n 50%\\n \\n \\n 75%\\n \\n \\n 100%\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n No\\n \\n \\n Yes\\n \\n \\n Churn\\n \\n \\n Relative Frequency\\n \\n \\n \\n Dependents\\n \\n \\n \\n \\n NO\\n \\n \\n YES\\n \\n \\n Distribution: Churn By Dependents\\n \\n\\n\",\"data:image/svg+xml;utf8,\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0\\n \\n \\n 200\\n \\n \\n 400\\n \\n \\n 600\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0\\n \\n \\n 20\\n \\n \\n 40\\n \\n \\n 60\\n \\n \\n Tenure\\n \\n \\n Frequency\\n \\n \\n \\n Churn\\n \\n \\n \\n \\n No\\n \\n \\n Yes\\n \\n \\n Distribution: Tenure By Churn\\n \\n\\n\",\"data:image/svg+xml;utf8,\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0%\\n \\n \\n 25%\\n \\n \\n 50%\\n \\n \\n 75%\\n \\n \\n 100%\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n No\\n \\n \\n Yes\\n \\n \\n Churn\\n \\n \\n Relative Frequency\\n \\n \\n \\n PhoneService\\n \\n \\n \\n \\n NO\\n \\n \\n YES\\n \\n \\n Distribution: Churn By PhoneService\\n \\n\\n\",\"data:image/svg+xml;utf8,\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0%\\n \\n \\n 25%\\n \\n \\n 50%\\n \\n \\n 75%\\n \\n \\n 100%\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n No\\n \\n \\n Yes\\n \\n \\n Churn\\n \\n \\n Relative Frequency\\n \\n \\n \\n MultipleLines\\n \\n \\n \\n \\n NO\\n \\n \\n YES\\n \\n \\n Distribution: Churn By MultipleLines\\n \\n\\n\",\"data:image/svg+xml;utf8,\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0%\\n \\n \\n 25%\\n \\n \\n 50%\\n \\n \\n 75%\\n \\n \\n 100%\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n No\\n \\n \\n Yes\\n \\n \\n Churn\\n \\n \\n Relative Frequency\\n \\n \\n \\n InternetService\\n \\n \\n \\n \\n \\n DSL\\n \\n \\n FIBER OPTIC\\n \\n \\n NO\\n \\n \\n Distribution: Churn By InternetService\\n \\n\\n\",\"data:image/svg+xml;utf8,\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0%\\n \\n \\n 25%\\n \\n \\n 50%\\n \\n \\n 75%\\n \\n \\n 100%\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n No\\n \\n \\n Yes\\n \\n \\n Churn\\n \\n \\n Relative Frequency\\n \\n \\n \\n OnlineSecurity\\n \\n \\n \\n \\n NO\\n \\n \\n YES\\n \\n \\n Distribution: Churn By OnlineSecurity\\n \\n\\n\",\"data:image/svg+xml;utf8,\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0%\\n \\n \\n 25%\\n \\n \\n 50%\\n \\n \\n 75%\\n \\n \\n 100%\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n No\\n \\n \\n Yes\\n \\n \\n Churn\\n \\n \\n Relative Frequency\\n \\n \\n \\n OnlineBackup\\n \\n \\n \\n \\n NO\\n \\n \\n YES\\n \\n \\n Distribution: Churn By OnlineBackup\\n \\n\\n\",\"data:image/svg+xml;utf8,\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0%\\n \\n \\n 25%\\n \\n \\n 50%\\n \\n \\n 75%\\n \\n \\n 100%\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n No\\n \\n \\n Yes\\n \\n \\n Churn\\n \\n \\n Relative Frequency\\n \\n \\n \\n DeviceProtection\\n \\n \\n \\n \\n NO\\n \\n \\n YES\\n \\n \\n Distribution: Churn By DeviceProtection\\n \\n\\n\",\"data:image/svg+xml;utf8,\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0%\\n \\n \\n 25%\\n \\n \\n 50%\\n \\n \\n 75%\\n \\n \\n 100%\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n No\\n \\n \\n Yes\\n \\n \\n Churn\\n \\n \\n Relative Frequency\\n \\n \\n \\n TechSupport\\n \\n \\n \\n \\n NO\\n \\n \\n YES\\n \\n \\n Distribution: Churn By TechSupport\\n \\n\\n\",\"data:image/svg+xml;utf8,\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0%\\n \\n \\n 25%\\n \\n \\n 50%\\n \\n \\n 75%\\n \\n \\n 100%\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n No\\n \\n \\n Yes\\n \\n \\n Churn\\n \\n \\n Relative Frequency\\n \\n \\n \\n StreamingTV\\n \\n \\n \\n \\n NO\\n \\n \\n YES\\n \\n \\n Distribution: Churn By StreamingTV\\n \\n\\n\",\"data:image/svg+xml;utf8,\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0%\\n \\n \\n 25%\\n \\n \\n 50%\\n \\n \\n 75%\\n \\n \\n 100%\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n No\\n \\n \\n Yes\\n \\n \\n Churn\\n \\n \\n Relative Frequency\\n \\n \\n \\n StreamingMovies\\n \\n \\n \\n \\n NO\\n \\n \\n YES\\n \\n \\n Distribution: Churn By StreamingMovies\\n \\n\\n\",\"data:image/svg+xml;utf8,\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0%\\n \\n \\n 25%\\n \\n \\n 50%\\n \\n \\n 75%\\n \\n \\n 100%\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n No\\n \\n \\n Yes\\n \\n \\n Churn\\n \\n \\n Relative Frequency\\n \\n \\n \\n Contract\\n \\n \\n \\n \\n \\n MONTH-TO-MONTH\\n \\n \\n ONE YEAR\\n \\n \\n TWO YEAR\\n \\n \\n Distribution: Churn By Contract\\n \\n\\n\",\"data:image/svg+xml;utf8,\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0%\\n \\n \\n 25%\\n \\n \\n 50%\\n \\n \\n 75%\\n \\n \\n 100%\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n No\\n \\n \\n Yes\\n \\n \\n Churn\\n \\n \\n Relative Frequency\\n \\n \\n \\n PaperlessBilling\\n \\n \\n \\n \\n NO\\n \\n \\n YES\\n \\n \\n Distribution: Churn By PaperlessBilling\\n \\n\\n\",\"data:image/svg+xml;utf8,\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0%\\n \\n \\n 25%\\n \\n \\n 50%\\n \\n \\n 75%\\n \\n \\n 100%\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n No\\n \\n \\n Yes\\n \\n \\n Churn\\n \\n \\n Relative Frequency\\n \\n \\n \\n PaymentMethod\\n \\n \\n \\n \\n \\n \\n BANK TRANSFER (AUTOMATIC)\\n \\n \\n CREDIT CARD (AUTOMATIC)\\n \\n \\n ELECTRONIC CHECK\\n \\n \\n MAILED CHECK\\n \\n \\n Distribution: Churn By PaymentMethod\\n \\n\\n\",\"data:image/svg+xml;utf8,\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0\\n \\n \\n 250\\n \\n \\n 500\\n \\n \\n 750\\n \\n \\n 1000\\n \\n \\n 1250\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 25\\n \\n \\n 50\\n \\n \\n 75\\n \\n \\n 100\\n \\n \\n MonthlyCharges\\n \\n \\n Frequency\\n \\n \\n \\n Churn\\n \\n \\n \\n \\n No\\n \\n \\n Yes\\n \\n \\n Distribution: MonthlyCharges By Churn\\n \\n\\n\",\"data:image/svg+xml;utf8,\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0\\n \\n \\n 500\\n \\n \\n 1000\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0\\n \\n \\n 2500\\n \\n \\n 5000\\n \\n \\n 7500\\n \\n \\n TotalCharges\\n \\n \\n Frequency\\n \\n \\n \\n Churn\\n \\n \\n \\n \\n No\\n \\n \\n Yes\\n \\n \\n Distribution: TotalCharges By Churn\\n \\n\\n\",\"data:image/svg+xml;utf8,\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 0.0%\\n \\n \\n 25.0%\\n \\n \\n 50.0%\\n \\n \\n 75.0%\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n Low\\n \\n \\n Medium\\n \\n \\n PredictivePower\\n \\n \\n Relative Frequency\\n \\n \\n \\n PredictivePower\\n \\n \\n \\n \\n Low\\n \\n \\n Medium\\n \\n \\n Predictive power of features\\n \\n\\n\"],\"slickOpts\":{\"dots\":true}}],\"evals\":[],\"jsHooks\":[]} \nIt is important to keep in mind that this type of bivariate analysis cannot detect combinatorial effects that exist among multiple variables to affect churn. Therefore, just because a variable do not appear to be differently distributed in terms of churn behaviour, such as Gender, it should not be excluded from analysis as it may be significant when considered in combination with other variables. Nevertheless, this is a good start for seeing if there are “learnable” signals in the dataset.\nThe output also includes a dataframe with summary statistics pertaining to variable type, presence of outliers, and descriptive statistics.\n## Import libraries library(knitr) library(kableExtra) ## Preview data kable(t(head(autoEDA_results$overview, 4)), colnames=NULL) %\u0026gt;% kable_styling(bootstrap_options = c(\u0026quot;striped\u0026quot;, \u0026quot;hover\u0026quot;))    1  2  3  4      Feature  Churn  Contract  Dependents  DeviceProtection    Observations  7032  7032  7032  7032    FeatureClass  character  character  character  character    FeatureType  Categorical  Categorical  Categorical  Categorical    PercentageMissing  0  0  0  0    PercentageUnique  0.03  0.04  0.03  0.03    ConstantFeature  No  No  No  No    ZeroSpreadFeature  No  No  No  No    LowerOutliers  0  0  0  0    UpperOutliers  0  0  0  0    ImputationValue  NO  MONTH-TO-MONTH  NO  NO    MinValue  0  0  0  0    FirstQuartile  0  0  0  0    Median  0  0  0  0    Mean  0  0  0  0    Mode  NO  MONTH-TO-MONTH  NO  NO    ThirdQuartile  0  0  0  0    MaxValue  0  0  0  0    LowerOutlierValue  0  0  0  0    UpperOutlierValue  0  0  0  0    PredictivePowerPercentage  0  46  17  7    PredictivePower  Low  Medium  Low  Low     In the last row, there is a handy PredictivePower metric for each input variable with respect to a specified target variable. For now, we can ignore this as I will cover it in more details in a later post examining variable importance.\n ExPanDaR: interactive data exploration ExPanDaR provides a really nifty Shiny app for interactive explorations of your data set. Originally designed for examining time-series data, the package requires the input dataframe to have a 1) time/date column and 2) a column that uniquely identifies each row. As the time/date column is only needed if you want to visualize time-dependent trends, to use a dataset without a time dimension you can just add a new numeric column (ts) with a constant and set that as the time dimension. An index column would suffice for the second requirement. In the original Telco dataset, the customerID column would have worked fine. As I had dropped it in the process of data cleaning, I will just add a new index column (ID).\n## Import library library(ExPanDaR) ## Add mock time column and new index to dataframe cleaned_df$ts \u0026lt;- rep(1, nrow(cleaned_df)) cleaned_df$ID \u0026lt;- seq.int(nrow(cleaned_df)) To start up the Shiny app for interactive exploration of the results:\nExPanD(df = cleaned_df, cs_id = \u0026quot;ID\u0026quot;, ts_id = \u0026quot;ts\u0026quot;) Here are some snapshots of the features that I find most useful. The dropdown menus and sliders make it really easy and flexible to examine any combinations of variables.\n         To go beyond bivariate relationships, the scatter plot can aggregate information from up to four variables and really give some interesting insights.\n   There are some other very cool features like allowing the user to generate and explore new variables (from some arithemtic combinations of existing variables) on the fly and performing regression analysis. Definitely give this package a try!\n     ","permalink":"/post/fast-exploratory-data-analysis-for-the-impatient/","tags":["EDA","Python","R"],"title":"Fast exploratory data analysis for when you just can't wait"},{"categories":["Dev handbook"],"contents":" \n --       \n Where do we start with version control? It’s a bit finicky, often neglected, but oh-so important.\nOne of the key components of building good habits is to make the action easy to do. So here we round up the (usual) cheat sheets and some fun tools that make learning/remembering those git commands a little easier.\nCheat sheet Of course, to start us off, the official cheat sheet from Github:\n \nGit Explorer As promised, here is a fun one:\n     ","permalink":"/post/version-control-git-handbook/","tags":["Git"],"title":"Version control with Git"},{"categories":["Data science toolbox"],"contents":" \n --       \n Getting data Data wrangling Analysis Association rule mining  RFM analysis Survival analysis Time-series analysis Machine learning Supervised learning Unsupervised learning Reporting     ","permalink":"/post/data-science-for-business/","tags":["Python","R","Survival analysis","Association rule mining"],"title":"Data science for business"},{"categories":["Data science toolbox"],"contents":" \n --       \n While examining feature importance is most commonly thought of as something to do after building a machine learning model, it can and should also be done before performing any serious data analysis, as both a sanity check and a time saver.\nSeeing which input features are the most predictive of the target feature can reveal potential problems with the dataset and/or the need to add more features to the dataset. Ultimately, narrowing down the entire feature space to a core set of variables that are the most predictive of the target variable is key to building successful data models.\nHere you will find a collection of model-independent and dependent approaches for exploring the “informativeness” of variables in a dataset.\nUnsupervised model-agnostic approaches Factor analysis of mixed-type data Hierarchical clustering of variables Supervised model-agnostic approaches Variable similarity Correlation-based Information theory Model-dependent approaches Random forest     ","permalink":"/post/exploring-variable-importance/","tags":["EDA","Variable importance"],"title":"Exploring variable importance "},{"categories":["Web development"],"contents":"\r\n\r\r\r\r\r\r\r\n\rMaking your own website or app is a great creative outlet. This is a continuously updated repository of free (or reasonably priced) resources for spicing up the UI/UX:\nIllustrations\rFor those of us who are utterly not artistically inclined, jazz up landing pages and blog posts with these fantastic free illustration. Many of the images you see on this site are taken from these sites:\n\r\nIcons \u0026amp; Glyphs\rPepper these through out to keep things interesting:\n\r\r\r\r\r","permalink":"/post/ui-and-ux-resources/","tags":["UI","UX"],"title":"Handy UI and UX resources "},{"categories":["Careers"],"contents":" \n --       \n There may exist some people in this world who enjoy job hunting, but we have not met one of them yet. As data scientist/developer jobs are becoming more and more popular, it is all the more important to know how to keep track of the most interesting opportunity and make your application to stand out. Here are a continuously updating suite of tools and services that we have tried or want to try for getting that next job.\nResumes One way to get yourself to stop putting off writing or updating your resume is make doing it fun and attractive. Remember the good old days of fiddling with Microsoft Word margins to get that two-column look just right? In recent years, almost too many online resume template/building platforms have popped up to keep track of. Here we have a collection of such platforms that offer at least some level of free services.\nFor creating the “official” resume to be send out, our favourites are CakeResume and Flow CV, as they offer the most innovative interfaces, generous free tiers and just the right amount of flexibility. For something a bit different, Qwilir offers templates to create a single-page web document to display the most salient points of your resume, which can be linked as part of a professional portfolio. Nevertheless, as everyone’s resume needs and aesthetic sensibilities differ, it might be worthwhile to look through each of the links below to find one that you particularly like.\n\n \nFinally, we have not tried it yet, but Resume Worded offers a free AI-powered review of your data science resume to check for important key words.\n    ","permalink":"/post/job-hunting-tools/","tags":["Job search","Resume","Useful"],"title":"Make job hunting fun again (kind of)"},{"categories":["Data science toolbox"],"contents":" \n --       \n Matplotlib Create single plot The figure object holds all subplots and other plot elements inside it. A figure object can have one or more subplots inside it called axes, arranged in rows and columns. Every figure has at least one axes. The axes objects have no relation to the x- or y-axis.\nMatplotlib (version \u0026gt;= 1.4) has a range of styles available for the plots. Yan Holtz of the Python Graph Gallery has made a nice panel view of all of them:\n    ## Import libraries import matplotlib.pyplot as plt ## Set style plt.style.use(\u0026#39;seaborn-ticks\u0026#39;) ## Initiate figure fig, ax = plt.subplots(figsize=(8, 3)) ## Create lot plt.plot([1,2,3,4,5], [1,2,3,4,10], \u0026#39;go\u0026#39;, label=\u0026#39;GreenDots\u0026#39;) # green dots plt.plot([1,2,3,4,5], [2,3,4,5,11], \u0026#39;b*\u0026#39;, label=\u0026#39;Bluestars\u0026#39;) # blue stars ## Label plot plt.title(\u0026#39;A Simple Scatterplot\u0026#39;, fontsize=20) plt.xlabel(\u0026#39;O\u0026#39;, fontsize=18) plt.ylabel(\u0026#39;Y\u0026#39;, fontsize=18) plt.xlim([0, 6]) ## (0, 6) plt.ylim([0, 12]) ## (0, 12) plt.tick_params(axis=\u0026#39;both\u0026#39;, which=\u0026#39;major\u0026#39;, labelsize=14) ## Legend ## \u0026#39;best\u0026#39; prevents legend from overlapping with plot elements #plt.legend(title=\u0026#39;Group\u0026#39;, loc=\u0026#39;best\u0026#39;, fontsize=12) ax.legend(title=\u0026quot;Legend Title\u0026quot;, fontsize=6, title_fontsize=6) ## Show plot plt.show() Create subplots Initiate grid\n## Set up subplot grid fig, axes = plt.subplots(nrows = 9, ncols = 2, sharex = False, sharey = False, figsize=(8, 15))  With a for loop To delete a blank subplot:\nfig.subplots_adjust(top=0.92, wspace=0.2, hspace=0.3) plt.tight_layout() fig.delaxes(axes[8][1])  Seaborn Plotly Plotly does not need much introduction, as it is now very widely used to create interactive plots in both Python and R.\n Plotting  For a while, one major drawback of Plotly is its, in my opinion, rather inconvenient syntax, where the source data needs to be passed in as arrays even though most of us want to be able to plot data directly from dataframes. cufflinks package, which bridges pandas and Plotly, the release of Plotly Express\n Styling  Plotnine One of the strengths of the R language is its very powerful graphing package ggplot2, with its distinctive implementation of Leland Wilkinson’s Grammar of Graphics. The Plotnine package brings this (at least part of it, it seems for now) capability to Python, with very little change to the R syntax. Here is a (ever growing) collection of useful links curated by us to get your started with using Plotnine.\nThe brackets around the ggplot() function call looks strange at first, but it is needed for the signature multi-line ggplot2 grammer to work:\n## Import libraries import pandas as pd from plotnine import * from random import randint # Generate dataset random_numbers = [randint(1, 100) for p in range(0, 100)] df = pd.DataFrame({\u0026#39;number\u0026#39;: random_numbers}) # Draw plot p = ( ggplot(df, aes(x=\u0026#39;number\u0026#39;)) + geom_histogram(bins=20, na_rm=True) + ggtitle(\u0026#39;Histogram of random numbers\u0026#39;) + theme_light() ) ## Display plot p.draw(); If you want to save the plot to file:\np.save(\u0026quot;output.png\u0026quot;) And just because I can see myself wanting to use these plots in a Streamlit app, here is a working template:\nimport pandas as pd import numpy as np from plotnine import * import streamlit as st n = 10 df = pd.DataFrame({\u0026#39;x\u0026#39;: np.arange(n), \u0026#39;y\u0026#39;: np.arange(n), \u0026#39;yfit\u0026#39;: np.arange(n) + np.tile([-.2, .2], n // 2), \u0026#39;cat\u0026#39;: [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;] * (n // 2)}) a = ( ggplot(df) + geom_col(aes(\u0026#39;x\u0026#39;, \u0026#39;y\u0026#39;)) ) fig = a.draw(); ## Needed to remove the \u0026quot;ggplot\u0026lt;#\u0026gt;\u0026quot; message st.pyplot() Yellowbrick x \u0026lt;- 7 y \u0026lt;- 9 x + y ## [1] 16 o = c(\u0026#39;hello\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;2\u0026#39;) print(o) ## [1] \u0026quot;hello\u0026quot; \u0026quot;1\u0026quot; \u0026quot;2\u0026quot;     ","permalink":"/post/graphing-in-python-a-walkthrough/","tags":["Visualizations","Python"],"title":"Graphing in Python - A walkthrough"},{"categories":["Web development"],"contents":" \n --      h3 {font-size: 24px;}    \n Having made a few websites/web apps using Django, Blogdown and Shiny, some HTML and CSS snippets have turned out to be useful time and time again. Not being professional front-end developers, we thought it would probably be a good idea to create an easy-to-reference repository of them for future projects.\nNavigation Tabs Tabs are a great way to display information that you might want to compare side-by-side. The horizontal layout also helps to save on space. I always opt for the Bootstrap tabsets, as they are very easy and consistent to implement:\n\nTab 1  Tab 2  Tab 3     Image credit: Icons 8       Image credit: Icons 8       Image credit: Icons 8       \nTo make this:\n\u0026lt;div class=\u0026quot;container\u0026quot;\u0026gt; \u0026lt;!-- Nav tabs --\u0026gt; \u0026lt;ul class=\u0026quot;nav nav-pills nav-justified\u0026quot; role=\u0026quot;tablist\u0026quot;\u0026gt; \u0026lt;li class=\u0026quot;nav-item active\u0026quot;\u0026gt; \u0026lt;a class=\u0026quot;nav-link active\u0026quot; data-toggle=\u0026quot;tab\u0026quot; href=\u0026quot;#tab1\u0026quot;\u0026gt;\u0026lt;font size=\u0026quot;+2\u0026quot;\u0026gt;\u0026lt;b\u0026gt;Tab 1\u0026lt;/b\u0026gt;\u0026lt;/font\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;nav-item\u0026quot;\u0026gt; \u0026lt;a class=\u0026quot;nav-link\u0026quot; data-toggle=\u0026quot;tab\u0026quot; href=\u0026quot;#tab2\u0026quot;\u0026gt;\u0026lt;font size=\u0026quot;+2\u0026quot;\u0026gt;\u0026lt;b\u0026gt;Tab 2\u0026lt;/b\u0026gt;\u0026lt;/font\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;nav-item\u0026quot;\u0026gt; \u0026lt;a class=\u0026quot;nav-link\u0026quot; data-toggle=\u0026quot;tab\u0026quot; href=\u0026quot;#tab3\u0026quot;\u0026gt;\u0026lt;font size=\u0026quot;+2\u0026quot;\u0026gt;\u0026lt;b\u0026gt;Tab 3\u0026lt;/b\u0026gt;\u0026lt;/font\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;!-- Tab panes --\u0026gt; \u0026lt;div class=\u0026quot;tab-content\u0026quot;\u0026gt; \u0026lt;div id=\u0026quot;tab1\u0026quot; class=\u0026quot;container tab-pane active\u0026quot;\u0026gt; Tab 1 content \u0026lt;/div\u0026gt; \u0026lt;div id=\u0026quot;tab2\u0026quot; class=\u0026quot;container tab-pane fade\u0026quot;\u0026gt; Tab 2 content \u0026lt;/div\u0026gt; \u0026lt;div id=\u0026quot;tab3\u0026quot; class=\u0026quot;container tab-pane fade\u0026quot;\u0026gt; Tab 3 content \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \nFloating outline When the page has a lot of content, it is very helpful to include a floating table of contents on the side of the page that shows the reader where they are. You can see an example of this on the left!\nAfter experimenting with a few options, I found that the steps outlined here by Aidan Feldman work most easily and the best for Blogdown sites:\n\u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt; \u0026lt;meta name=\u0026quot;viewport\u0026quot; content=\u0026quot;width=device-width, initial-scale=1\u0026quot;\u0026gt; \u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.css\u0026quot; /\u0026gt; \u0026lt;script src=\u0026quot;https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026quot;https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026quot;https://maxcdn.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026quot;https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;body data-spy=\u0026quot;scroll\u0026quot; data-target=\u0026quot;#toc\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;container\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;!-- sidebar, which will move to the top on a small screen --\u0026gt; \u0026lt;div class=\u0026quot;col-sm-2\u0026quot;\u0026gt; \u0026lt;nav id=\u0026quot;toc\u0026quot; data-toggle=\u0026quot;toc\u0026quot; class=\u0026quot;sticky-top\u0026quot; style=\u0026#39;padding-top:40px\u0026#39;\u0026gt;\u0026lt;/nav\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;!-- main content area --\u0026gt; \u0026lt;div class=\u0026quot;col-sm-10\u0026quot;\u0026gt; \u0026lt;!-- Page content --\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \nIf there are headings that you do not want to be included in the outline, you can change the header HTML tag, like \u0026lt;h2\u0026gt;, to \u0026lt;h2 data-toc-skip\u0026gt;.\n\nStyling Font size The font size of specific sections of text can be altered, either by relative change:\n\u0026lt;font size=\u0026quot;+2\u0026quot;\u0026gt;This is bigger text.\u0026lt;/font\u0026gt; Or by setting the absolute size (1-7):\n\u0026lt;font size=\u0026quot;1\u0026quot;\u0026gt;This is really tiny text.\u0026lt;/font\u0026gt; \nCode blocks We love the ability to use both Python and R code in a single Rmarkdown post on Blogdown sites. With that, it would be nice to be able to easily visually distinguish Python and R code blocks. Here are some CSS stylings used on this site:\ncode{ /* Base styling for all code blocks */ padding: 3px 5px; background: #ffffff; border: 1px solid $border-color; border-radius: 3px; color: $text-color-dark; } .python { background: #ffffff; border-color: #F6B156; border-style: dotted; page-break-inside: avoid; font-family: monospace; font-size: 15px; line-height: 1.6; margin-bottom: 1.6em; max-width: 100%; overflow: auto; padding: 1em 1.5em; display: block; word-wrap: break-word; } .r { background: #ffffff; border-color: #03d944; border-style: dotted; page-break-inside: avoid; font-family: monospace; font-size: 15px; line-height: 1.6; margin-bottom: 1.6em; max-width: 100%; overflow: auto; padding: 1em 1.5em; display: block; word-wrap: break-word; }     ","permalink":"/post/neat-html-snippets-to-jazz-up-your-site/","tags":["Useful"],"title":"HTML and CSS snippets to jazz up your site"},{"categories":["Data science toolbox"],"contents":"\rAs useful as they are, and they really are, Jupyter notebooks can feel rather stale after a few years. While they are great for quickly testing out code and exploring datasets, I can’t help but want something more fun and polished for presenting a completed project.\nFor this reason I had been working largely in R for the past while, despite my preference for the simplicity of the Python syntax, in large part due to the vibrant Shiny ecosystem that makes creating dashboards and interactive web apps easy and fun. However, I am happy to report that in really just the past year or so, the interactive app/dashboard scene in Python has really flourished, first with the appearance of the Plotly Dash platform and then most recently with Streamlit. Here is a (ever updating) round-up of my experiences so far with Python packages that allow us to bring our data science projects to life.\n\nStreamlit\r\rPlotly Dash\r\rVoilà\r\r\rWhat really drew me back to Python is the appearance of Streamlit, an open-source library that really truly makes converting a data analysis workflow to an app a breeze. By adding a few magic commands, a Python script is spun to an interactive app that can be deployed on Heroku like any other web app.\n\n\r\nInitially, Streamlit seemed to me neither here nor there, sitting somewhere between Plotly Dash and Jupyter notebooks. While it seemed very easy to worked with, I thought that it was missing the “look” of Dash and also the versatility of cell-based operations of Jupyter. However, as soon as I gave it a try, I totally understood the allure.\nThe absolute best feature of Streamlit, in my opinion, is how easy it is to create interactive widgets like dropdown menus, radio boxes, sliders and even text/number inputs, without needing to write any callbacks. Using an example from the official documentation, this is how to create and get input from a slider:\nimport streamlit as st\rage = st.slider(\u0026#39;How old are you?\u0026#39;, 0, 130, 25)\rst.write(\u0026quot;I\u0026#39;m \u0026quot;, age, \u0026#39;years old\u0026#39;)\rCreating other types of interactive widgets in Streamlit is just as easy. You can find a list of functionalities currently supported here.\nIn comparison, this is how to create the same thing in Plotly Dash:\nimport dash\rimport dash_html_components as html\rimport dash_core_components as dcc\rapp = dash.Dash(__name__, external_stylesheets=external_stylesheets)\rapp.layout = html.Div([\rdcc.Slider(\rid=\u0026#39;my-slider\u0026#39;,\rmin=0,\rmax=20,\rstep=0.5,\rvalue=10,\r),\rhtml.Div(id=\u0026#39;slider-output-container\u0026#39;)\r])\r@app.callback(\rdash.dependencies.Output(\u0026#39;slider-output-container\u0026#39;, \u0026#39;children\u0026#39;),\r[dash.dependencies.Input(\u0026#39;my-slider\u0026#39;, \u0026#39;value\u0026#39;)])\rdef update_output(value):\rreturn \u0026#39;You have selected \u0026quot;{}\u0026quot;\u0026#39;.format(value)\rif __name__ == \u0026#39;__main__\u0026#39;:\rapp.run_server(debug=True)\r\rOf course, Plotly Dash provides many other functionalities that Streamlit is not capable of, at least for now. However, the simplicity of working with Streamlit makes it so satistfying to quickly whip up an interactive app to showcase your work.\nFor example, I have made two Streamlit apps to host my microlearning series on survival analysis and building a random forest classifier to predict customer churn. I made them both multipage apps that allow progressive reveal of the content at the learner’s pace, in order to take advantage of the easy interactive widgets to the fullest extent. Granted that I had the workflow written out before hand, but making either one of these apps took only 2-3 days. Check them out!\n\nSurvival analysis\r\rRandom forest\r\r\r\r\r\r\rIf you are interested in trying Streamlit out, there are several demo apps listed in the documentation linked above. In addition, many enthusiastic adopters of Streamlit have tweeted about their own creations.\n\r\r\rPlotly Dash has been around for quite a while now, so I will not go as much in depth here, trusting that everyone is already pretty familiar with it. Unlike the other two packages introduced here, Dash has the benefit of the very large and active Plotly community to serve as a solid knowledge base to support users of all levels.\nAs of now, Plotly Dash just cannot be beat in terms of how polished its end products look. It is my package of choice if I need to create a dashboard/app that will be used by non-technical end users, such as business professionals, with clear interactive features and sophisticated crosstalk between elements (i.e. data tables, plots, maps, etc.). For example, here is a sales dashboard that I had made while learning the Dash platform.\nHowever, as mentioned in comparison with Streamlit, the Dash code base can get quite large and complex very quickly, particularly when used with the built-in or Bootstrap grid system for layout. Consequently, it has a fairly steep learning curve, with very rewarding results. On a related note, I cannot recommend enough the Dash Bootstrap Components package, which greatly simplifies the implementations of a lot of layout and interactive features with the added benefit of the clean Bootstrap look.\nWant to get started on your own? For an step-by-step guide to building a professional dashboard, take a look at the video below made by a Plotly developer:\n\r\n\rFinally, just because we want to upgrade from Jupyter notebooks does not mean we are going to do away with it completely, as it is still a fantastic platform for exploring data and prototyping analysis workflows. In addition, the ability to use Python and R together in the same notebook makes it indispensible for data scientists who want the best of both worlds: ease of data wrangling in Python but mature analysis packages in R. Since so many of us begin a project in Jupyter notebooks, it would be a dream come true to be able to make dashboards/interactive apps from the analysis results right there. The recently released package Voilà grants that wish, somewhat.\nHere is an introduction to the package at SciPy 2019:\n\n\r\nWhile interactive widgets like dropdown menus and sliders can be added to the dashboard, as you can do in Streamlit and Plotly Dash, using the ipywidgets library, I have personally found the syntax much less clear and not as many tutorials/help pages available to get a newcomer started. In addition, as Voilà is still in very early stages of development, the resulting dashboard/app looks rather barebones as compared to Dash. Here is an “learning dashboard” that I had made using Voilà to introduce various model-agnostic approaches to calculate feature importance, for comparison with the sales dashboard made with Dash.\nNevertheless, as mentioned above, one strength of Jupyter notebooks is the ability to use other language kernels. Any language that is supported by a Jupyter kernel can be used to create a Voilà app, so for projects where that is needed, this would be the package for you.\n\r\r\r\n\r\nTaken together, it is really an exciting time for finally being able to communicate/present your Python data science projects in style. This post will be updated as new features and packages become available, so please check back once in a while! :)\n","permalink":"/post/making-python-apps/","tags":["Dash","Jupyter","Streamlit","Voila","Python"],"title":"Going beyond Jupyter notebooks"},{"categories":null,"contents":"Welcome to Intelligence Refinery!\nWe are Nancy and Mihai Chelaru-Centea, two neuroscience majors who not so long ago ditched the lab notebooks for Jupyter notebooks. With the explosion of the data science field, there is a bewildering number of articles, tutorials, Stackoverflow answers, courses and packages on the internet for anyone who cares to look. Like many other newcomers, we are navigating this ever rising sea of information, and often misinformation, with varying degrees of success each day.\nAfter having worked for some time as data scientist/developers and meeting others on the same path, we realized the importance of creating a dedicated repository in which we can continuously refine and grow our professional knowledge, so as to be able to keep pace with this fast moving field. So, we rolled up our sleeves and built this site, where we try to distill everything we are learning about data science, software development, and anything else of interest into helpful nuggets for ourselves and whoever else that may stumble onto this site.\nWe hope that you enjoy your time here, and would love to hear any comments or questions that you have!\n","permalink":"/about/about/","tags":null,"title":"About Us"}]